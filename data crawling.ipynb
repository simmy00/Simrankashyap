{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a82a9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\asus\\anaconda3\\lib\\site-packages (3.1.2)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\asus\\anaconda3\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\asus\\anaconda3\\lib\\site-packages (3.1.2)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\asus\\anaconda3\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Title: Rise of Cyber Crime and its Effects\n",
      "Article Text: Cybercrime is the most discussed problem in the twenty-first century. The usage of cell phones and the internet is increasing dramatically over the world, which is generating questions about consumers’ security and privacy. Because of this, all users must understand cybercrime and security. Cybercrime is defined as organised criminal conduct carried out by attackers online. Cybercrime comes in numerous forms, such as fraud, computer viruses, cyberstalking, and others. Due to these, businesses and government organisations are spending more on maintaining and employing professionals in cybercrime.\n",
      "7 Cyber security keywords: –\n",
      "1- Artificial Intelligence\n",
      "AI has been around for quite a while now and one of its most memorable advancements was the Go game between ‘AlphaGo’, a computer Go program developed by Google DeepMind, and the world champion Lee Se-dol. AlphaGo was able to use its collected data to achieve its goal. The so-called ‘weak AI’ used on AlphaGo is also applied to various fields within cyber security.\n",
      "2. Ransomware\n",
      "Over the past years, ransomware has been aiming at innumerable targets. However, its new method of attack now aims at specific targets, where companies, communities, and public institutions are at risk. Companies with strong financial powers are most likely to be their targets as the attackers will be rewarded huge sums of money for their success. Those providing Infra and Database storage, local government and healthcare organizations, are listed as the main targets of ransomware attacks.\n",
      "3. Supply Chain Attack\n",
      "A supply chain attack is a cyber-attack that affects the organization by targeting less-secure elements in the supply network. Supply Chain attacks were already on the list of the 7 Cybersecurity keywords last year, and still manage to maintain their place. Such attacks will continue to infiltrate the supply chain through third-party systems and services. Therefore, due to its weak security systems, those purchasing third-party vendor products and services must take extra caution.\n",
      "4. Cloud\n",
      "The interest in Cloud Security is on the rise. However, it is pointed out that Cloud computing’s largest vulnerability is the operator’s configuration error. More complex and flexible Cloud systems will eventually lead to a greater number of errors and reveal itself as a target for many cyber attackers.\n",
      "5. Malicious emails\n",
      "Receiving emails containing malware is not a new thing anymore. The Financial Security Institute warns us how malware email attacks are becoming more cunning and harder to block. Spear Phishing, a traditional method of attack that uses HWP and DOC documents, will not stop this year.\n",
      "6. Internet of Things (IoT)\n",
      "Building castles in the air was the perfect phrase to describe how IoT was perceived. However, IoT has now become a part of our lives. People can now watch YouTube on their refrigerators and gas valves can be closed by using Smartphone applications. Many are experiencing an easier lifestyle but are also suffering from many cyber threats.\n",
      "7. Darkweb\n",
      "Due to several incidents, Darkweb, which was only known to cyber attackers and security professionals, is now well-known to the public. For example, Warez and Webhard are the two programs in which Netizens in Korea can improve their networking skills but also leads them to be involved in distributing illegal programs and even in cybercrime.\n",
      "There are millions and billions of users and websites in the vast community known as cyberspace. People utilise it for a variety of activities including e-commerce, transactions, shopping, movies, music, and video games. Anyone can simply access anything online in the current technological era owing to an accessible internet connection. As a result, crime in general and cybercrime, in particular, have surged dramatically. Additionally, the faster internet connection has greatly boosted the rate of data circulation. All of these problems are responsible for why cyber security has grown to be a significant issue for society.\n",
      "The government has created several cybercrime-related laws to curb the spread of crime and to protect people’s interests. These laws also provide a defence against cybercrime. Aside from that, the government has established cyber cells in police stations to combat cybercrime as quickly as possible.\n",
      "Cybercrime is an attack that can be harmful to both an individual and a business. There have been several instances where a Cyber Attack led to a data leak that caused a significant loss for a business or a person. These cyber-attacks could have negative effects on the country and the business. The countless instances of cyberattacks that have taken place in India and other nations have necessitated increased security measures. There are four main categories of cybercrime, according to a popular definition—hacking, money, privacy, and cyber-terrorism.\n",
      "Cybercrime is a type of crime in which illegal activities are carried out online or using computers. Cybercrime comes in a variety of forms which involves harassing online users. Cybercrime is the most serious and rapidly expanding type of crime in this day and age. Any person’s life may be negatively impacted for a very long time by becoming a cyber victim. Cybercrimes have a wide range of repercussions on financial and investment activity in digital organisations.\n",
      "One typical tactic used by criminals is to lure online users in by creating attractive websites and sending phoney emails purporting to be from banks or other organisations and asking for personal information. It makes it easier for criminals to access a person’s bank account and personal data. Due to viruses, mail fraud, account hacking, and software piracy, people have been victims of cybercrimes. They also run into problems with unauthorised access mailing, threats from pornographic emails, and video transmission.\n",
      "Types of Cyber Crime\n",
      "Current working directory: C:\\Users\\Asus\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl\n",
    "!pip install openpyxl --upgrade\n",
    "import openpyxl\n",
    "openpyxl.__version__\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Sample URL\n",
    "url = 'https://insights.blackcoffer.com/rise-of-cyber-crime-and-its-effects/'\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract article title\n",
    "title_element = soup.find('h1', class_='entry-title')\n",
    "if title_element:\n",
    "    title = title_element.text.strip()\n",
    "else:\n",
    "    title = \"Title Not Found\"\n",
    "\n",
    "# Extract article text\n",
    "article_text_element = soup.find('div', class_='td-post-content')\n",
    "if article_text_element:\n",
    "    paragraphs = article_text_element.find_all('p')\n",
    "    article_text = '\\n'.join([p.text.strip() for p in paragraphs])\n",
    "else:\n",
    "    article_text = \"Article Text Not Found\"\n",
    "\n",
    "# Print title and text (for testing)\n",
    "print(f\"Title: {title}\")\n",
    "print(f\"Article Text: {article_text}\")\n",
    "\n",
    "# Save extracted data to a text file (URL_ID.txt)\n",
    "def save_to_file(title, text):\n",
    "    with open('URL_ID.txt', 'w', encoding='utf-8') as file:\n",
    "        file.write(f\"{title}\\n\")\n",
    "        file.write(f\"{text}\")\n",
    "\n",
    "# Call the save_to_file function to save data\n",
    "save_to_file(title, article_text)\n",
    "\n",
    "import os\n",
    "print(\"Current working directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaa6b84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\asus\\anaconda3\\lib\\site-packages (0.18.0.post0)\n",
      "Requirement already satisfied: nltk in c:\\users\\asus\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\asus\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\asus\\anaconda3\\lib\\site-packages (from nltk) (1.1.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\asus\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install textblob nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63ed70e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49d0c10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Textual analysis completed and saved to URLtxt_Output_Data_Structure.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Function to perform textual analysis\n",
    "def perform_text_analysis(text):\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Word Frequency\n",
    "    word_freq = Counter(tokens)\n",
    "    \n",
    "    # Sentiment Analysis\n",
    "    blob = TextBlob(text)\n",
    "    sentiment = blob.sentiment.polarity\n",
    "    \n",
    "    # Named Entity Recognition (NER) - Not implemented in this example\n",
    "    \n",
    "    return tokens, word_freq, sentiment\n",
    "\n",
    "# Load the extracted article text from the file\n",
    "with open('URL_ID.txt', 'r', encoding='utf-8') as file:\n",
    "    article_text = file.read()\n",
    "\n",
    "# Perform textual analysis\n",
    "tokens, word_freq, sentiment = perform_text_analysis(article_text)\n",
    "\n",
    "# Create a DataFrame for the word frequency\n",
    "df_word_freq = pd.DataFrame(list(word_freq.items()), columns=['Word', 'Frequency'])\n",
    "\n",
    "# Sort the DataFrame by word frequency in descending order\n",
    "df_word_freq = df_word_freq.sort_values(by='Frequency', ascending=False)\n",
    "\n",
    "# Create a DataFrame for sentiment analysis\n",
    "df_sentiment = pd.DataFrame({'Sentiment': [sentiment]})\n",
    "\n",
    "# Concatenate DataFrames\n",
    "df = pd.concat([df_word_freq, df_sentiment], axis=1)\n",
    "\n",
    "# Save the computed variables into an Excel file\n",
    "df.to_excel('Output_Data_Structure.xlsx', index=False)\n",
    "\n",
    "print(\"Textual analysis completed and saved to URLtxt_Output_Data_Structure.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2040163a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\asus\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: textblob in c:\\users\\asus\\anaconda3\\lib\\site-packages (0.18.0.post0)\n",
      "Requirement already satisfied: textstat in c:\\users\\asus\\anaconda3\\lib\\site-packages (0.7.3)\n",
      "Requirement already satisfied: click in c:\\users\\asus\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\asus\\anaconda3\\lib\\site-packages (from nltk) (1.1.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\asus\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: pyphen in c:\\users\\asus\\anaconda3\\lib\\site-packages (from textstat) (0.15.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk textblob textstat\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932894ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61698f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c9871d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4189ba68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be2a8c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Word', 'Frequency', 'Sentiment']\n",
      "Textual analysis completed and saved to Output_Data_Structure.xlsx\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "from textstat import syllable_count\n",
    "\n",
    "# Load the input data from Input.xlsx\n",
    "input_df = pd.read_excel('C:/Users/Asus/URLtxt_Output_Data_Structure.xlsx')\n",
    "print(input_df.columns.tolist())\n",
    "\n",
    "# Load NLTK stopwords\n",
    "nltk_stopwords = set(stopwords.words('english'))\n",
    "\n",
    "# Function to perform textual analysis\n",
    "def perform_text_analysis(text):\n",
    "    # Tokenization and sentence segmentation (split by periods)\n",
    "    tokens = word_tokenize(text)\n",
    "    sentences = text.split('.')\n",
    "    \n",
    "    # Clean tokens by removing stopwords and punctuation\n",
    "    cleaned_tokens = [word.lower() for word in tokens if word.isalpha() and word.lower() not in nltk_stopwords]\n",
    "    \n",
    "    # Compute derived variables\n",
    "    word_count = len(cleaned_tokens)\n",
    "    sentence_count = len(sentences)\n",
    "    avg_sentence_length = word_count / sentence_count if sentence_count != 0 else 0\n",
    "    complex_word_count = sum(1 for word in cleaned_tokens if syllable_count(word) >= 3)\n",
    "    percentage_complex_words = (complex_word_count / word_count) * 100 if word_count != 0 else 0\n",
    "    fog_index = 0.4 * (avg_sentence_length + percentage_complex_words)\n",
    "    avg_word_length = sum(len(word) for word in cleaned_tokens) / word_count if word_count != 0 else 0\n",
    "    \n",
    "    # Sentiment analysis using TextBlob\n",
    "    blob = TextBlob(text)\n",
    "    polarity_score = blob.sentiment.polarity\n",
    "    subjectivity_score = blob.sentiment.subjectivity\n",
    "    \n",
    "    # Personal pronouns count\n",
    "    personal_pronouns = sum(1 for word in cleaned_tokens if word.lower() in ['i', 'we', 'my', 'ours', 'us'])\n",
    "    \n",
    "    return word_count, sentence_count, avg_sentence_length, complex_word_count, percentage_complex_words, fog_index, avg_word_length, polarity_score, subjectivity_score, personal_pronouns\n",
    "\n",
    "# Perform textual analysis for each article\n",
    "results = []\n",
    "for index, row in input_df.iterrows():\n",
    "    article_text = row['Word']\n",
    "    analysis_result = perform_text_analysis(article_text)\n",
    "    results.append(analysis_result)\n",
    "\n",
    "# Create an output DataFrame\n",
    "output_df = pd.DataFrame(results, columns=['Word Count', 'Sentence Count', 'Avg Sentence Length', 'Complex Word Count', 'Percentage of Complex Words', 'FOG Index', 'Avg Word Length', 'Polarity Score', 'Subjectivity Score', 'Personal Pronouns'])\n",
    "\n",
    "# Concatenate input and output DataFrames\n",
    "final_df = pd.concat([input_df, output_df], axis=1)\n",
    "\n",
    "# Save the results to an Excel file\n",
    "final_df.to_excel('Output_Data_Structure.xlsx', index=False)\n",
    "\n",
    "print(\"Textual analysis completed and saved to Output_Data_Structure.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616bce10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c79593",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33c1ab0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
